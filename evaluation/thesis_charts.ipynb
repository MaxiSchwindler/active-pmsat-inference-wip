{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## User Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = r\"../server_results/learning_results_10_accuracy2\"\n",
    "SAVE_FIGURES_TO = \"thesis_charts/GnuServer\"  # or None to just show figures\n",
    "STYLE = \"thesis\"  # \"thesis\": styled like my thesis (times new roman, etc); \"latex\": default latex look\n",
    "\n",
    "USES_ORACLE = False\n",
    "\n",
    "if USES_ORACLE:\n",
    "        ALGORITHM_NAMES = {\n",
    "        \"APMSL('ONLY_RW')\": 'APMSL (ic, rw)',\n",
    "        \"APMSL('RW', orpg=True)\": 'APMSL (ic, rw, replay, repro)',\n",
    "    \n",
    "        \"GSM('PURGE')\": 'GSM (purge, rw)',\n",
    "        \"GSM('NO_PURGE')\": 'GSM (no-purge, rw)',\n",
    "    }\n",
    "else:\n",
    "    ALGORITHM_NAMES = {\n",
    "        \"APMSL('ONLY_RW')\": 'APMSL (ic, rw, term-impr)',\n",
    "        \"APMSL('ONLY_RW', 'GTT2')\": 'APMSL (ic, rw, term-thresh2)',\n",
    "        \"APMSL('RW', orpg=True)\": 'APMSL (ic, rw, replay, repro, term-impr)',\n",
    "        \"APMSL('RW', 'GTT2', orpg=True)\": 'APMSL (ic, rw, replay, repro, term-thresh2)',\n",
    "    \n",
    "        \"GSM('PURGE')\": 'GSM (purge, rw, term-bisim)',\n",
    "        \"GSM('NO_PURGE')\": 'GSM (no-purge, rw, term-bisim)',\n",
    "    }\n",
    "\n",
    "BASE_ALGORITHM_HATCHES = {\n",
    "    \"APMSL\": \"xxx\",\n",
    "    \"GSM\": \"...\",\n",
    "}\n",
    "\n",
    "BASE_ALGORITHM_COLORMAP = {\n",
    "    \"APMSL\": \"plasma\",\n",
    "    \"GSM\": \"viridis\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports & Misc Setup\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(f\"..\")\n",
    "sys.path.append(r\"../../pmsat-inference\")\n",
    "sys.path = [r\"../../AALpy\"] + sys.path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from evaluation.utils import print_results_info, print_results_info_per_alg, TracedMooreSUL\n",
    "import evaluation.charts as charts\n",
    "import evaluation.charts_pandas as charts_pd\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    os.makedirs(SAVE_FIGURES_TO, exist_ok=True)\n",
    "    \n",
    "PRECISION_KEY = \"Precision_v2\"\n",
    "RECALL_KEY = \"Recall_v2\"\n",
    "FSCORE_KEY = \"F-Score_v2\"\n",
    "\n",
    "ACCURACY_KEY = \"Accuracy\"\n",
    "ACCURACY_NAME = \"Accuracy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, results_df = charts.load_results(RESULTS_DIR, remove_traces_used_to_learn=True, is_server_results=True, as_pandas=True)\n",
    "print(f\"Loaded {len(results)} results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_result_if(result):\n",
    "    return False\n",
    "\n",
    "def postprocess_result(result):\n",
    "    if result[\"algorithm_name\"] in ALGORITHM_NAMES:\n",
    "        result[\"algorithm_name\"] = ALGORITHM_NAMES[result[\"algorithm_name\"]]\n",
    "    else:\n",
    "        print(f'Warning: \"{result[\"algorithm_name\"]}\" not found in algorithm_names!')\n",
    "\n",
    "    return result\n",
    "\n",
    "def filter_results(results):\n",
    "    if isinstance(results, pd.DataFrame):\n",
    "        mask = results.apply(lambda r: not remove_result_if(r), axis=1)\n",
    "        filtered_df = results[mask].copy()\n",
    "        return filtered_df.apply(postprocess_result, axis=1)\n",
    "    else:\n",
    "        return [postprocess_result(r) for r in results if not remove_result_if(r)]\n",
    "\n",
    "results = filter_results(results)\n",
    "results_df = filter_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Plot Config (automatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"default\")  # initialize to default - seaborn overrides!\n",
    "\n",
    "# color map creation\n",
    "CM_OFFSET = 2\n",
    "ALL_ALGORITHMS_IN_RESULTS = sorted(results_df[\"algorithm_name\"].unique().tolist())\n",
    "ALGORITHM_COLORS = {}\n",
    "ALGORITHM_HATCHES = {}\n",
    "for base_alg, colormap in BASE_ALGORITHM_COLORMAP.items():\n",
    "    alg_versions = [a for a in ALL_ALGORITHMS_IN_RESULTS if a.startswith(base_alg)]\n",
    "    colormap = plt.get_cmap(BASE_ALGORITHM_COLORMAP[base_alg], lut=len(alg_versions) + CM_OFFSET)\n",
    "    for i, alg_version in enumerate(alg_versions):\n",
    "        color = colormap(i + (CM_OFFSET // 2))\n",
    "        ALGORITHM_COLORS[alg_version] = color\n",
    "        ALGORITHM_HATCHES[alg_version] = BASE_ALGORITHM_HATCHES.get(base_alg, '')\n",
    "\n",
    "if STYLE == \"latex\":\n",
    "    mpl.rcParams.update({\n",
    "        \"text.usetex\": False,  # True if LaTeX is installed\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"CMU Serif\"],  # download from https://ctan.org/pkg/cm-unicode\n",
    "        \"axes.labelsize\": 12,\n",
    "        \"font.size\": 12,\n",
    "        \"legend.fontsize\": 10,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "        \"axes.titlesize\": 14\n",
    "    })\n",
    "\n",
    "elif STYLE == \"thesis\":\n",
    "    mpl.rcParams.update({\n",
    "        # Fonts\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\", \"Times\", \"DejaVu Serif\"],\n",
    "        \"font.size\": 11,                # Match thesis body text\n",
    "        \"axes.titlesize\": 13,           # Section-style figure titles\n",
    "        \"axes.labelsize\": 11,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "\n",
    "        # Axes & Lines\n",
    "        \"axes.linewidth\": 1.0,\n",
    "        \"lines.linewidth\": 1.5,\n",
    "        \"lines.markersize\": 6,\n",
    "\n",
    "        # Legend\n",
    "        \"legend.fontsize\": 10,\n",
    "        \"legend.title_fontsize\": 10,\n",
    "        \"legend.handlelength\": 1.8,\n",
    "        \"legend.handleheight\": 0.8,\n",
    "        \"legend.borderaxespad\": 0.8,\n",
    "        \"legend.borderpad\": 0.5,\n",
    "        \"legend.labelspacing\": 0.4,\n",
    "        \"legend.handletextpad\": 0.5,\n",
    "        \"legend.columnspacing\": 1.2,\n",
    "        \"legend.fancybox\": False,\n",
    "\n",
    "        # Figure\n",
    "        # \"figure.dpi\": 300,\n",
    "        \"savefig.dpi\": 300,\n",
    "        # \"figure.figsize\": (9, 6),  # Good for 2-column layout\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "\n",
    "        # Ticks\n",
    "        \"xtick.major.size\": 4,\n",
    "        \"xtick.major.width\": 0.8,\n",
    "        \"ytick.major.size\": 4,\n",
    "        \"ytick.major.width\": 0.8,\n",
    "\n",
    "        # PDF output\n",
    "        \"pdf.fonttype\": 42,  # Ensures text remains text in PDFs\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def bar_chart_pd(\n",
    "    ax,\n",
    "    df: pd.DataFrame,\n",
    "    key: str,\n",
    "    agg_method: str,\n",
    "    group_by: list[str],\n",
    "    title: str,\n",
    "    xlabel: str,\n",
    "    ylabel: str,\n",
    "    y_as_percentage: bool = False,\n",
    "    x_as_percentage: bool = False,\n",
    "    show_num_results_on_bar: bool = False,\n",
    "    legend: bool = True,\n",
    "    bar_label_fontsize: int = 10,\n",
    "    bar_label_decimal_digits: int = 2,\n",
    "    simple: bool = False,\n",
    ") -> tuple[list, list]:\n",
    "    \"\"\"Draws a bar chart on the given `ax`, and returns legend handles and labels.\"\"\"\n",
    "\n",
    "    pivot_df = df.groupby(by=group_by)[key].agg(agg_method).unstack().astype(float)\n",
    "    if y_as_percentage:\n",
    "        pivot_df *= 100\n",
    "\n",
    "    pivot_df.plot(kind=\"bar\", ax=ax, width=0.92, xlabel=xlabel, ylabel=ylabel, rot=0, legend=False, title=title)\n",
    "    if simple:\n",
    "        # don't do anything except plotting - no visual adjustments\n",
    "        return [], []\n",
    "\n",
    "    num_groups = len(pivot_df.index)\n",
    "    margin = 0.92 / 2  # half bar width\n",
    "    padding = 0.1  # extra space on sides\n",
    "    ax.set_xlim(-margin - padding, num_groups - 1 + margin + padding)\n",
    "\n",
    "    def percent_label(value, *args, **kwargs):\n",
    "        suffix = kwargs.get('suffix', '%')\n",
    "        return (f\"{value:.0f}\" if value % 1 == 0 else f\"{value:.1f}\") + suffix\n",
    "\n",
    "    # percentage formatting\n",
    "    if y_as_percentage:\n",
    "        for bars in ax.containers:\n",
    "            ax.bar_label(bars, labels=[percent_label(v) for v in bars.datavalues], fontsize=bar_label_fontsize)\n",
    "        ax.yaxis.set_major_formatter(mtick.FuncFormatter(percent_label))\n",
    "    else:\n",
    "        for bars in ax.containers:\n",
    "            ax.bar_label(bars, fmt=f\"%.{bar_label_decimal_digits}f\", fontsize=bar_label_fontsize)\n",
    "\n",
    "    if x_as_percentage:\n",
    "        ax.set_xticklabels([percent_label(x) for x in pivot_df.index])\n",
    "    else:\n",
    "        ax.set_xticklabels([x for x in pivot_df.index])\n",
    "        \n",
    "    # number of results on bar\n",
    "    if show_num_results_on_bar:\n",
    "        assert len(group_by) == 2, f\"Only works with exactly two group-by entries!\"\n",
    "        grouped_df = df.groupby(by=group_by)\n",
    "        result_counts = {\n",
    "            key: len(group)\n",
    "            for key, group in grouped_df\n",
    "        }\n",
    "        for bars in ax.containers:\n",
    "            col_key = bars.get_label()\n",
    "            count_labels = []\n",
    "            for i, row_key in enumerate(pivot_df.index):\n",
    "                row_key_tuple = (row_key, ) if not isinstance(row_key, tuple) else row_key\n",
    "                group_key = row_key_tuple + (col_key,)\n",
    "                count = result_counts.get(group_key, 0)\n",
    "                count_labels.append(f\"n={count}\")\n",
    "                # label = f\"n={count}\"\n",
    "                # \n",
    "                # bar = bars[i]\n",
    "                # x = bar.get_x() + bar.get_width() / 2\n",
    "                # y = bar.get_y()\n",
    "                # \n",
    "                # ax.text(\n",
    "                #     x, y-0.05,\n",
    "                #     label,\n",
    "                #     ha='center', va='top',\n",
    "                #     fontsize=bar_label_fontsize,\n",
    "                #     color='dimgray',\n",
    "                #     clip_on=False\n",
    "                # )\n",
    "                # \n",
    "                \n",
    "            \n",
    "            ax.bar_label(bars, labels=count_labels, fontsize=bar_label_fontsize, label_type='center', \n",
    "                         backgroundcolor='white', bbox=dict(alpha=0.75, \n",
    "                                                            color=\"white\", \n",
    "                                                            boxstyle=\"square, pad=0.05\",\n",
    "                                                            capstyle='round'), \n",
    "                         clip_on=False)\n",
    "\n",
    "    handles = []\n",
    "    labels = []\n",
    "\n",
    "    # hatches and colors\n",
    "    for bars in ax.containers:\n",
    "        bar_label = bars.get_label()\n",
    "        if bar_label in ALL_ALGORITHMS_IN_RESULTS:\n",
    "            algorithm = bar_label\n",
    "            hatch = ALGORITHM_HATCHES[algorithm]\n",
    "            color = ALGORITHM_COLORS[algorithm]\n",
    "        \n",
    "            for bar in bars:\n",
    "                if hatch:\n",
    "                    bar.set_facecolor(\"none\")\n",
    "                    bar.set_hatch(hatch)\n",
    "                    bar.set_edgecolor(color)\n",
    "                    bar.set_linewidth(1.2)\n",
    "                    patch_kwargs = dict(facecolor=\"none\", edgecolor=color, hatch=hatch + (hatch[0] * 2))\n",
    "                else:\n",
    "                    bar.set_facecolor(color)\n",
    "                    patch_kwargs = dict(facecolor=color)\n",
    "                \n",
    "            if bar_label not in labels:\n",
    "                patch = mpatches.Patch(label=bar_label, **patch_kwargs)\n",
    "                handles.append(patch)\n",
    "                labels.append(algorithm)\n",
    "\n",
    "    if legend:\n",
    "        ax.legend(handles=handles, labels=labels, title=\"Algorithm\", loc=\"best\")\n",
    "\n",
    "    return handles, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 8), sharex=True)\n",
    "handles, labels = bar_chart_pd(\n",
    "    ax1, results_df, \"learned_correctly\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Percentage of bisimilar results\", y_as_percentage=True, x_as_percentage=True,\n",
    "    title=\"Bisimilarity\", legend=True,\n",
    ")\n",
    "\n",
    "bar_chart_pd(\n",
    "    ax2, results_df, ACCURACY_KEY, agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=f\"Mean {ACCURACY_NAME} over all results\", x_as_percentage=True,\n",
    "    y_as_percentage=False, title=f\"{ACCURACY_NAME}\",\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "ax1.set_ylim(0, 105)\n",
    "ax2.set_ylim(0, 1.05)\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'correctness.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 8), sharex=True)\n",
    "# handles, labels = bar_chart_pd(\n",
    "#     ax1, results_df, PRECISION_KEY, agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "#     xlabel='Glitch percentage', ylabel=\"Precision\", y_as_percentage=False, x_as_percentage=True,\n",
    "#     title=\"Precision\", legend=True,\n",
    "# )\n",
    "# \n",
    "# bar_chart_pd(\n",
    "#     ax2, results_df, RECALL_KEY, agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "#     xlabel='Glitch percentage', ylabel=\"Recall\", x_as_percentage=True,\n",
    "#     y_as_percentage=False, title=\"Recall\",\n",
    "#     legend=False,\n",
    "# )\n",
    "# \n",
    "# ax1.set_ylim(0, 1.05)\n",
    "# ax2.set_ylim(0, 1.05)\n",
    "# \n",
    "# if SAVE_FIGURES_TO:\n",
    "#     plt.savefig(Path(SAVE_FIGURES_TO)/'precision_and_recall.png')\n",
    "# else:\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\n",
    "    (results_df[\"algorithm_name\"] == \"GSM (purge, rw)\") &\n",
    "    (results_df[\"glitch_percent\"] == 1.0)\n",
    "][\"learned_correctly\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r, not_ic_result in results_df[results_df[\"learned_model_input_complete\"] == False].iterrows():\n",
    "    learning_info = dict(not_ic_result[\"detailed_learning_info\"])\n",
    "    for r, i in learning_info.items():\n",
    "        print(f\"{r}: {i.get('num_additional_traces_preprocessing_input_completeness', None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "handles, labels = bar_chart_pd(\n",
    "    ax1, results_df, \"timed_out\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Percentage of timed-out results\", y_as_percentage=True, x_as_percentage=True,\n",
    "    title=\"\", legend=False, bar_label_fontsize=6\n",
    ")\n",
    "\n",
    "bar_chart_pd(\n",
    "    ax2, results_df, \"timed_out\", agg_method=\"mean\", group_by=[\"original_automaton_size\", \"algorithm_name\"],\n",
    "    xlabel='Number of states in the ground truth model', ylabel=\"Percentage of timed-out results\", y_as_percentage=True,\n",
    "    title=\"\", legend=False, x_as_percentage=False,bar_label_fontsize=6\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Time-Outs\", y=1.25)\n",
    "\n",
    "legend_columns = len(ALL_ALGORITHMS_IN_RESULTS) / 2\n",
    "if legend_columns <= 2:\n",
    "    if len(ALL_ALGORITHMS_IN_RESULTS) <= 5:\n",
    "        legend_columns = len(ALL_ALGORITHMS_IN_RESULTS)\n",
    "        \n",
    "fig.legend(\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    title=\"Algorithm\",\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, 1.2),\n",
    "    ncol=legend_columns,\n",
    ")\n",
    "\n",
    "ax1.set_ylim(0, 105)\n",
    "ax2.set_ylim(0, 105)\n",
    "\n",
    "ax1.set_title(\"Per glitch percentage\", fontsize=12)\n",
    "ax2.set_title(\"Per number of states\", fontsize=12)\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'timeouts.png', bbox_inches='tight')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 7), sharex=True)\n",
    "\n",
    "timed_out_results = results_df[results_df['timed_out']]\n",
    "\n",
    "handles, labels = bar_chart_pd(\n",
    "    ax1, timed_out_results, \"learned_correctly\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Percentage of bisimilar timed-out results\", y_as_percentage=True, x_as_percentage=True,\n",
    "    title=\"Bisimilarity of timed-out results\", legend=True, show_num_results_on_bar=True,\n",
    ")\n",
    "\n",
    "bar_chart_pd(\n",
    "    ax2, timed_out_results, ACCURACY_KEY, agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Mean Accuracy over timed-out results\", x_as_percentage=True,\n",
    "    y_as_percentage=False, title=\"Accuracy of timed-out results\",\n",
    "    legend=False, show_num_results_on_bar=True,\n",
    ")\n",
    "\n",
    "ax1.set_ylim(0, 105)\n",
    "ax2.set_ylim(0, 1.05)\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'timed_out_correctness.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 7), sharex=True)\n",
    "\n",
    "not_timed_out_results = results_df[results_df['timed_out'] == False]\n",
    "\n",
    "handles, labels = bar_chart_pd(\n",
    "    ax1, not_timed_out_results, \"learned_correctly\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Percentage of bisimilar non-timed-out results\", y_as_percentage=True, x_as_percentage=True,\n",
    "    title=\"Bisimilarity of non-timed-out results\", legend=True, show_num_results_on_bar=True,\n",
    ")\n",
    "\n",
    "bar_chart_pd(\n",
    "    ax2, not_timed_out_results, ACCURACY_KEY, agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Mean Accuracy over non-timed-out results\", x_as_percentage=True,\n",
    "    y_as_percentage=False, title=\"Accuracy of non-timed-out results\", show_num_results_on_bar=True,\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "ax1.set_ylim(0, 105)\n",
    "ax2.set_ylim(0, 1.05)\n",
    "\n",
    "print(labels)\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'not_timed_out_correctness.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg_name in not_timed_out_results[\"algorithm_name\"].unique():\n",
    "    print(alg_name)\n",
    "    for gp in [1,5,10]:\n",
    "        print(f\"{gp}%\")\n",
    "        print(len(not_timed_out_results[not_timed_out_results[\"algorithm_name\"] == alg_name][not_timed_out_results[\"glitch_percent\"] == gp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(1, 1, figsize=(9, 5), sharex=True)\n",
    "# \n",
    "# not_bisim_out_results = results_df[results_df['learned_correctly'] == False]\n",
    "# \n",
    "# bar_chart_pd(\n",
    "#     ax1, not_bisim_out_results, ACCURACY_KEY, agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "#     xlabel='Glitch percentage', ylabel=\"Mean Accuracy over non-bisimilar results\", x_as_percentage=True,\n",
    "#     y_as_percentage=False, title=\"Accuracy of non-bisimilar results\",\n",
    "#     legend=True,\n",
    "# )\n",
    "# \n",
    "# ax1.set_ylim(0, 1.05)\n",
    "# \n",
    "# if SAVE_FIGURES_TO:\n",
    "#     plt.savefig(Path(SAVE_FIGURES_TO)/'not_bisim_correctness.png')\n",
    "# else:\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 8), sharex=True)\n",
    "handles, labels = bar_chart_pd(\n",
    "    ax1, results_df, \"learned_correctly\", agg_method=\"mean\", group_by=[\"original_automaton_size\", \"algorithm_name\"],\n",
    "    xlabel='Number of states in the ground truth model', ylabel=\"Percentage of bisimilar results\", y_as_percentage=True, x_as_percentage=False,\n",
    "    title=\"Bisimilarity\", legend=True,\n",
    ")\n",
    "\n",
    "bar_chart_pd(\n",
    "    ax2, results_df, ACCURACY_KEY, agg_method=\"mean\", group_by=[\"original_automaton_size\", \"algorithm_name\"],\n",
    "    xlabel='Number of states in the ground truth model', ylabel=\"Mean Accuracy over all results\", x_as_percentage=False,\n",
    "    y_as_percentage=False, title=\"Accuracy\",\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "ax1.set_ylim(0, 105)\n",
    "ax2.set_ylim(0, 1.05)\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'correctness_over_states.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.boxplot(\n",
    "    data=results_df,\n",
    "    x=\"glitch_percent\",\n",
    "    y=ACCURACY_KEY,\n",
    "    hue=\"algorithm_name\",\n",
    "    # fill=False,  # this colors the whiskers, but not the boxes itself - maybe i can use this and apply hatch myself?\n",
    "    palette=ALGORITHM_COLORS,\n",
    "    hue_order=ALL_ALGORITHMS_IN_RESULTS,\n",
    "    flierprops=dict(marker='o', markersize=3, alpha=0.3),\n",
    ")\n",
    "plt.title(\"Accuracy per Run\")\n",
    "\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Glitch percentage\")\n",
    "\n",
    "def percent_label(label):\n",
    "    return f\"{int(float(label))}%\"\n",
    "\n",
    "ax.set_xticklabels([percent_label(t.get_text()) for t in ax.get_xticklabels()])\n",
    "\n",
    "l = ax.legend(title=\"Algorithm\")\n",
    "\n",
    "# set hatches (& colors) # CAUTION: this might not work with other matplotlib / seaborn versions!\n",
    "patches = [p for p in ax.patches if type(p) == mpl.patches.PathPatch]\n",
    "num_groups = len(results_df[\"glitch_percent\"].unique())\n",
    "for alg_idx, alg in enumerate(ALL_ALGORITHMS_IN_RESULTS):\n",
    "    hatch = ALGORITHM_HATCHES[alg]\n",
    "    color = ALGORITHM_COLORS[alg]\n",
    "    for patch in patches[(alg_idx * num_groups):((alg_idx + 1) * num_groups)]:\n",
    "        if hatch:\n",
    "            # patch.set_fill(True)\n",
    "            patch.set_facecolor(\"none\")\n",
    "            patch.set_hatch(hatch)\n",
    "            patch.set_edgecolor(color)\n",
    "            patch.set_linewidth(1.2)\n",
    "\n",
    "# fix legend for hatches\n",
    "for lp, hatch in zip(l.get_patches(), ALGORITHM_HATCHES.values()):\n",
    "    lp.set_hatch((hatch + hatch[0] * 2))\n",
    "    fc = lp.get_facecolor()\n",
    "    lp.set_edgecolor(fc)\n",
    "    lp.set_facecolor('none')\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'accuracy_boxplot.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "quartiles = (\n",
    "    results_df.groupby(['algorithm_name', 'glitch_percent'])[ACCURACY_KEY]\n",
    "    .quantile([0.25, 0.5, 0.75])\n",
    "    .unstack(level=2)\n",
    "    .rename(columns={0.25: 'Q1', 0.5: 'Median', 0.75: 'Q3'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_boxplot_stats(group):\n",
    "    scores = group[ACCURACY_KEY]\n",
    "    q1 = scores.quantile(0.25)\n",
    "    q3 = scores.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_whisker = scores[scores >= q1 - 1.5 * iqr].min()\n",
    "    upper_whisker = scores[scores <= q3 + 1.5 * iqr].max()\n",
    "    outliers = scores[(scores < lower_whisker) | (scores > upper_whisker)].tolist()\n",
    "\n",
    "    return pd.Series({\n",
    "        'Q1': q1,\n",
    "        'Q3': q3,\n",
    "        'Median': scores.median(),\n",
    "        'IQR': iqr,\n",
    "        'Lower Whisker': lower_whisker,\n",
    "        'Upper Whisker': upper_whisker,\n",
    "        \"Number of Outliers\": len(outliers),\n",
    "        'Outliers': outliers\n",
    "    })\n",
    "\n",
    "# Group and apply the function\n",
    "boxplot_stats = (\n",
    "    results_df.groupby(['algorithm_name', 'glitch_percent'])\n",
    "      .apply(compute_boxplot_stats)\n",
    "      .reset_index()\n",
    ")\n",
    "boxplot_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 8), sharex=True)\n",
    "# handles, labels = bar_chart_pd(\n",
    "#     ax1, results_df, \"steps_learning\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "#     xlabel='Glitch percentage', ylabel=\"Mean number of steps per run\", x_as_percentage=True,\n",
    "#     title=\"Mean number of steps\", legend=True, bar_label_decimal_digits=1,\n",
    "# )\n",
    "# \n",
    "# bar_chart_pd(\n",
    "#     ax2, results_df, \"queries_learning\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "#     xlabel='Glitch percentage', ylabel=\"Mean number of queries per run\",\n",
    "#     title=\"Mean number of queries\", legend=False, bar_label_decimal_digits=1, x_as_percentage=True,\n",
    "# )\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(9, 5), sharex=True)\n",
    "handles, labels = bar_chart_pd(\n",
    "    ax1, results_df, \"steps_learning\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Mean number of steps per run\", x_as_percentage=True,\n",
    "    title=\"Mean number of steps\", legend=True, bar_label_decimal_digits=1,\n",
    ")\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'steps.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(9, 5), sharex=True)\n",
    "handles, labels = bar_chart_pd(\n",
    "    ax1, not_timed_out_results, \"steps_learning\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Mean number of steps per run in non-timed-out results\", x_as_percentage=True,\n",
    "    title=\"Mean number of steps (without timeouts)\", legend=True, bar_label_decimal_digits=1, show_num_results_on_bar=True,\n",
    ")\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'steps_without_timeouts.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"InformationPerStep\"] = results_df[ACCURACY_KEY] / results_df[\"steps_learning\"]\n",
    "results_df[\"InformationPerQuery\"] = results_df[ACCURACY_KEY] / results_df[\"queries_learning\"]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 8), sharex=True)\n",
    "handles, labels = bar_chart_pd(\n",
    "    ax1, results_df, \"InformationPerStep\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Information per step\", x_as_percentage=True,\n",
    "    title=\"Information per step\", legend=True, bar_label_decimal_digits=5,\n",
    ")\n",
    "\n",
    "bar_chart_pd(\n",
    "    ax2, results_df, \"InformationPerQuery\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Information per query\",\n",
    "    title=\"Information per query\", legend=False, bar_label_decimal_digits=5, x_as_percentage=True,\n",
    ")\n",
    "\n",
    "if False:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'info_per_steps_and_queries.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relplot(df, columns: list[str]):\n",
    "    ROWS = 2\n",
    "    MANUAL_LEGEND = True\n",
    "    GLITCH_PERCENTAGE_NAME = \"Glitch percentage\"\n",
    "    SHOW_GRID = False\n",
    "    \n",
    "    df[GLITCH_PERCENTAGE_NAME] = df[\"glitch_percent\"].apply(lambda x: f\"{int(x)}%\")  # so we can simply use the column title for relplot, and its already formatted\n",
    "    col_order = columns\n",
    "    \n",
    "    kwargs = dict()\n",
    "    if MANUAL_LEGEND:\n",
    "        kwargs[\"facet_kws\"] = dict(legend_out=False)\n",
    "    \n",
    "    g = sns.relplot(\n",
    "        df, \n",
    "        x=\"steps_learning\", y=ACCURACY_KEY, \n",
    "        col=\"algorithm_name\", col_wrap=ROWS, col_order=col_order,\n",
    "        hue=GLITCH_PERCENTAGE_NAME, style=GLITCH_PERCENTAGE_NAME, alpha=0.5, palette=[\"green\", \"blue\", \"red\"],\n",
    "        height=4, aspect=1.2, **kwargs,\n",
    "    )\n",
    "    g.figure.suptitle(\"Steps vs. Accuracy\", y=1.04)\n",
    "    g.set_titles(col_template=\"{col_name}\")\n",
    "    g.set_axis_labels(\"Steps\", \"Accuracy\")\n",
    "    \n",
    "    if MANUAL_LEGEND:\n",
    "        # sns.move_legend(\n",
    "        #     g, loc=\"upper center\", \n",
    "        #     title=None,\n",
    "        #     bbox_to_anchor=(0.5, 1.03),  # Centered above the entire figure\n",
    "        #     bbox_transform=g.figure.transFigure,\n",
    "        #     frameon=True,\n",
    "        #     ncol=results_df[GLITCH_PERCENTAGE_NAME].nunique(),\n",
    "        # )#, edgecolor='0.8', fancybox=True)\n",
    "        \n",
    "        # remove the existing legend\n",
    "        g._legend.remove()  \n",
    "    \n",
    "        handles, labels = g.axes[0].get_legend_handles_labels()\n",
    "        \n",
    "        # Insert title into first entry as a dummy handle\n",
    "        from matplotlib.lines import Line2D\n",
    "        title_handle = Line2D([], [], linestyle='None')  # No marker, empty handle\n",
    "        handles.insert(0, title_handle)\n",
    "        labels.insert(0, f\"{GLITCH_PERCENTAGE_NAME}:\")\n",
    "        \n",
    "        # Add custom legend\n",
    "        g.figure.legend(\n",
    "            handles,\n",
    "            labels,\n",
    "            loc=\"upper center\",\n",
    "            bbox_to_anchor=(0.5, 1.03),\n",
    "            bbox_transform=g.figure.transFigure,\n",
    "            ncol=len(labels),  # All on one row, including the title\n",
    "            frameon=True,\n",
    "            handletextpad=0.5,\n",
    "            # columnspacing=1.2,\n",
    "        )\n",
    "        \n",
    "    if SHOW_GRID:\n",
    "        for ax in g.axes.flatten():\n",
    "            ax.grid(True, which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "            \n",
    "    return g\n",
    "\n",
    "\n",
    "g = relplot(results_df, columns=ALL_ALGORITHMS_IN_RESULTS)\n",
    "if SAVE_FIGURES_TO:\n",
    "    g.savefig(Path(SAVE_FIGURES_TO)/'steps_vs_accuracy.png')\n",
    "    \n",
    "g2 = relplot(results_df, columns=[a for a in ALL_ALGORITHMS_IN_RESULTS if a.startswith(\"APMSL\")])\n",
    "if SAVE_FIGURES_TO:\n",
    "    g2.savefig(Path(SAVE_FIGURES_TO)/'steps_vs_accuracy_apmsl.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.scatterplot(\n",
    "    data=results_df,\n",
    "    x=\"steps_learning\",\n",
    "    y=ACCURACY_KEY,\n",
    "    hue=\"algorithm_name\",\n",
    "    style=\"glitch_percent\",\n",
    "    #size=\"queries_learning\",\n",
    "    palette=ALGORITHM_COLORS,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title(\"Accuracy vs. Steps\")\n",
    "# ax.set_xlabel(\"Steps\")\n",
    "# ax.set_ylabel(\"Accuracy\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[[\"algorithm_name\", \"glitch_percent\", \"original_automaton\"]].drop_duplicates().values  # unique combos\n",
    "\n",
    "group_cols = [\"algorithm_name\", \"glitch_percent\", \"original_automaton\"]\n",
    "target_metric = ACCURACY_KEY\n",
    "\n",
    "divergence = results_df.groupby(group_cols)[target_metric].std().reset_index()\n",
    "divergence = divergence.rename(columns={target_metric: \"within_group_std\"})\n",
    "\n",
    "stats_per_unique_run_combo = results_df.groupby(group_cols)[target_metric].agg(\n",
    "    mean=\"mean\", std=\"std\", min=\"min\", max=\"max\",\n",
    "    range=lambda x: x.max() - x.min()\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_models_df = (\n",
    "    results_df[[\"original_automaton\", \"original_automaton_size\", \"original_automaton_num_outputs\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(by=[\"original_automaton_size\", \"original_automaton_num_outputs\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "unique_models_df[\"model_index\"] = np.arange(len(unique_models_df))\n",
    "model_to_int = dict(zip(unique_models_df[\"original_automaton\"], unique_models_df[\"model_index\"]))\n",
    "results_df[\"model_index\"] = results_df[\"original_automaton\"].map(model_to_int)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 12), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "sizes = unique_models_df[\"original_automaton_size\"].values\n",
    "change_indices = np.where(np.diff(sizes) != 0)[0] + 0.5\n",
    "\n",
    "for i, algorithm in enumerate(ALL_ALGORITHMS_IN_RESULTS):\n",
    "    ax = axes[i]\n",
    "    subset = results_df[results_df[\"algorithm_name\"] == algorithm]\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=subset,\n",
    "        x=\"model_index\",\n",
    "        y=ACCURACY_KEY,\n",
    "        hue=\"glitch_percent\",\n",
    "        ax=ax,\n",
    "        palette=\"plasma\",\n",
    "        alpha=0.6,\n",
    "        legend=(i == 0)  # only show legend once\n",
    "    )\n",
    "\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.set_xlabel(\"\")  # common x label set below\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(algorithm)\n",
    "\n",
    "    # Draw vertical lines for size changes\n",
    "    for pos in change_indices:\n",
    "        ax.axvline(x=pos, color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # improve ticks for only bottom plots\n",
    "    # if i < len(ALL_ALGORITHMS_IN_RESUlTS) - 2:\n",
    "    #     ax.set_xticklabels([])\n",
    "\n",
    "# Common x-label and adjust layout  # TODO very manual...\n",
    "fig.text(0.5, -0.04, \"Model Index (sorted by number of states)\", ha='center', fontsize=12)\n",
    "fig.text(0.04, 0.5, \"Accuracy\", va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'accuracy_per_model_scatterplot.png')\n",
    "else:\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = [0, 1, 2, 30]\n",
    "fig, axes = plt.subplots(len(durations), 1, figsize=(9, 3 * len(durations)), sharex=True)\n",
    "\n",
    "for i, sec_per_step in enumerate(durations):\n",
    "    col_name = f\"FictionalRuntime_{sec_per_step}Sec\"\n",
    "    results_df[col_name] = results_df[\"total_time\"] + (results_df[\"steps_learning\"] * sec_per_step)\n",
    "\n",
    "    bar_chart_pd(\n",
    "        axes[i], results_df, col_name, agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "        xlabel='Glitch percentage', ylabel=\"Mean fictional runtime (sec)\",\n",
    "        x_as_percentage=True, legend=(i == 0), bar_label_decimal_digits=0, bar_label_fontsize=9,\n",
    "        title=f\"Mean Fictional Runtime ({sec_per_step} sec/step)\"\n",
    "    )\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'fictional_runtime.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "step_durations = np.arange(0, 31)  # from 0 to 30 seconds\n",
    "\n",
    "plot_data = []\n",
    "for sec_per_step in step_durations:\n",
    "    temp_df = results_df.copy()\n",
    "    temp_df[\"fictional_runtime\"] = temp_df[\"total_time\"] + temp_df[\"steps_learning\"] * sec_per_step\n",
    "\n",
    "    grouped = (\n",
    "        temp_df\n",
    "        .groupby([\"glitch_percent\", \"algorithm_name\"])[\"fictional_runtime\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    grouped[\"sec_per_step\"] = sec_per_step\n",
    "    plot_data.append(grouped)\n",
    "\n",
    "combined_df = pd.concat(plot_data)\n",
    "\n",
    "# unique_glitches = sorted(combined_df[\"glitch_percent\"].unique())\n",
    "unique_glitches = [1, 5]\n",
    "n = len(unique_glitches)\n",
    "\n",
    "fig, axes = plt.subplots(n, 1, figsize=(10, 4 * n), sharex=True)\n",
    "    \n",
    "for ax, glitch in zip(axes, unique_glitches):\n",
    "    subset = combined_df[combined_df[\"glitch_percent\"] == glitch]\n",
    "    \n",
    "    for algorithm_name, group in subset.groupby(\"algorithm_name\"):\n",
    "        ax.plot(group[\"sec_per_step\"], group[\"fictional_runtime\"], label=algorithm_name, color=ALGORITHM_COLORS[algorithm_name])\n",
    "\n",
    "    ax.set_title(f\"Fictional runtime vs. per-step duration ({glitch:.0f}% glitches)\")\n",
    "    ax.set_ylabel(\"Fictional runtime (sec)\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "axes[-1].set_xlabel(\"Assumed time per step (sec)\")\n",
    "\n",
    "if SAVE_FIGURES_TO:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'fictional_runtime_linecharts_by_glitch.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(9, 5), sharex=True)\n",
    "handles, labels = bar_chart_pd(\n",
    "    ax1, results_df, \"learning_rounds\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Mean number of learning rounds per run\", x_as_percentage=True,\n",
    "    title=\"Mean number of learning rounds\", legend=True, bar_label_decimal_digits=1,\n",
    ")\n",
    "\n",
    "if False:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'learning_rounds.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 8), sharex=True)\n",
    "handles, labels = bar_chart_pd(\n",
    "    ax1, results_df, \"steps_eq_oracle\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Mean number of steps in the EQ oracle per round\", x_as_percentage=True,\n",
    "    title=\"Mean number of EQ oracle steps\", legend=True, bar_label_decimal_digits=1,\n",
    ")\n",
    "\n",
    "bar_chart_pd(\n",
    "    ax2, results_df, \"queries_eq_oracle\", agg_method=\"mean\", group_by=[\"glitch_percent\", \"algorithm_name\"],\n",
    "    xlabel='Glitch percentage', ylabel=\"Mean number of queries in the EQ oracle per round\", x_as_percentage=True,\n",
    "    title=\"Mean number of EQ oracle queries\", legend=True, bar_label_decimal_digits=1,\n",
    ")\n",
    "\n",
    "if False:\n",
    "    plt.savefig(Path(SAVE_FIGURES_TO)/'learning_rounds.png')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
