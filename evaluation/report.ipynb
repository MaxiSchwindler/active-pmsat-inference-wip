{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "USE_LOCAL_AALPY = True\n",
    "\n",
    "GROUP_BY_MODEL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f\"..\")\n",
    "sys.path.append(r\"../pmsat-inference\")\n",
    "if USE_LOCAL_AALPY:\n",
    "    sys.path = [r\"../../AALpy\"] + sys.path\n",
    "\n",
    "from evaluation.utils import print_results_info, print_results_info_per_alg, TracedMooreSUL\n",
    "from evaluation.charts import *\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Loading Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "results_dir = r\"../learning_results_11\"  #  python evaluation/learn_automata.py -a \"APMSL\" \"APMSL(ONLY_RW)\" \"APMSL(RW)\" \"APMSL(NO_REP)\" \"APMSL(NO_REP, RW)\" -o \"None\" -n 3 -ns 3-8 -ni 3 -no 3 --learn_num_times 3 --glitch_percent 0.0 1.0 5.0 --glitch_mode \"enter_random_state\"\n",
    "results_dir = r\"../learning_results_12\"  #  python evaluation/learn_automata.py -a \"APMSL\" \"APMSL(ONLY_RW)\" -o \"None\" -n 3 -ns 3-6 -ni 3 -no 3 --learn_num_times 3 --glitch_percent 1.0 --glitch_mode \"enter_random_state\"  # mit 'sul_transitions'\n",
    "results_dir = r\"../learning_results_16\"  # python evaluation/learn_automata.py -o \"None\" -n 3 -ns 3-6 -ni 3 -no 3 --learn_num_times 3 --glitch_percent 1.0 --glitch_mode \"enter_random_state\" -a \"APMSL\" \"APMSL(ONLY_RW)\" \"APMSL(RW)\" \"APMSL(TC)\" \"APMSL(NO_REP, RW)\"\n",
    "results_dir = r\"../learning_results_17\"  # python evaluation/learn_automata.py -o \"None\" \"Random\" -n 3 -ns 3-8 -ni 3 -no 3 --learn_num_times 3 --glitch_percent 0.0 1.0 5.0 --glitch_mode \"enter_random_state\" -a \"APMSL\" \"APMSL(ONLY_RW)\" \"APMSL(RW)\" \"APMSL(TC)\" \"APMSL(NO_REP, RW)\"\n",
    "results_dir = r\"../learning_results_18\"  # python evaluation/learn_automata.py -o \"None\" -n 3 -ns 4-6 -ni 3 -no 3 --learn_num_times 2 --glitch_percent 0.0 0.1 --glitch_mode \"enter_random_state\" -a \"APMSL(tc=0)\" \"APMSL(tc=100)\" \"APMSL(tc=500)\"\n",
    "results_dir = r\"../learning_results_19\"  # python evaluation/learn_automata.py -o \"None\" -n 3 -ns 4-6 -ni 3 -no 3 --learn_num_times 2 --glitch_percent 0.0 1.0 --glitch_mode \"enter_random_state\" -a \"APMSL(tc=0)\" \"APMSL(tc=100)\" \"APMSL(tc=500)\" \"APMSL(tc=1000)\" \"APMSL(ONLY_RW)\"\n",
    "results_dir = r\"../learning_results_20\"  # no deduplicate_traces!  # python evaluation/learn_automata.py -o \"None\" -n 3 -ns 3-6 -ni 3 -no 3 --learn_num_times 3 --glitch_percent 1.0 --glitch_mode \"enter_random_state\" -a \"APMSL\" \"APMSL(ONLY_RW)\" \"APMSL(RW)\" \"APMSL(tc=500)\" \"APMSL(NO_REP, RW)\"\n",
    "# 22 # python evaluation/learn_automata.py -o \"None\" -n 3 -ns 7 -ni 3 -no 3 --learn_num_times 2 --glitch_percent 0.0 1.0 5.0 --glitch_mode \"enter_random_state\" -a \"APMSL\" \"APMSL(ONLY_RW)\" \"APMSL(RW)\" \"APMSL(tc=500)\" \"APMSL(NO_REP, RW)\"  # (also no duplication)\n",
    "# 23 # python evaluation/learn_automata.py -o \"None\" -n 3 -ns 7 -ni 3 -no 3 --learn_num_times 2 --glitch_percent 0.0 1.0 5.0 --glitch_mode \"enter_random_state\" -a \"APMSL\" \"APMSL(ONLY_RW)\" \"APMSL(RW)\" \"APMSL(tc=500)\" \"APMSL(NO_REP, RW)\"  # (also no duplication) (only replay glitches on peak)\n",
    "# 24 # python evaluation/learn_automata.py -o \"None\" \"Random\" -n 3 -ns 3-6 -ni 3 -no 3 --learn_num_times 3 --glitch_percent 0.0 1.0 5.0 --glitch_mode \"enter_random_state\" -a \"APMSL\" \"APMSL(ONLY_RW)\" \"APMSL(RW)\" \"APMSL(tc=500)\" \"APMSL(NO_REP, RW)\" # no deduplication, only replay glitches on peak\n",
    "# 25 # python evaluation/learn_automata.py -o \"None\" -n 10 -ns 3-9 -ni 3 -no 3 --learn_num_times 3 --glitch_percent 0.0 1.0 5.0 --glitch_mode \"enter_random_state\" -a \"APMSL\" \"APMSL(ddt=False)\" \"APMSL(ddt=False, orpg=True)\" \"APMSL(ONLY_RW)\" \"APMSL(ONLY_RW, ddt=True)\" \"APMSL(RW)\" \"APMSL(RW, ddt=False)\" \"APMSL(RW, ddt=False, orgp=True)\" \"APMSL(tc=500)\" \"APMSL(tc=500, ddt=False)\" \"APMSL(NO_REP, RW, ddt=False)\"  # interrupted when starting 7state \n",
    "# 26: python evaluation/learn_automata.py --learn_all_automata_from_dir example_automata/moore -a \"APMSL(RW)\" -o \"Random\" \"None\"  # terminated by MemoryError\n",
    "# 34:  python evaluation/learn_automata.py --files example_automata/moore -a \"APMSL(RW)\" \"APMSL(ONLY_RW)\" \"APMSL\" -o \"Random\" \"None\" --glitch_mode \"enter_random_state\" --glitch_percent 0.0 1.0\n",
    "\n",
    "results_dir = r\"../learning_results_49\"\n",
    "\n",
    "results = load_results(results_dir)\n",
    "print(f\"Loaded {len(results)} results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_result_if(result):\n",
    "    if result[\"algorithm_name\"] == \"APMSL('RW', ddt=False, orgp=True)\":\n",
    "        # typo in orpg -> always failed. remove\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def postprocess_result(result):\n",
    "    if result[\"algorithm_name\"] == \"APMSL('ONLY_RW', ddt=True)\":\n",
    "        # ddt=True is default anyways, so we can combine\n",
    "        result[\"algorithm_name\"] = \"APMSL('ONLY_RW')\"\n",
    "    \n",
    "    if result[\"algorithm_name\"].endswith(\"()\"):\n",
    "        # remove empty braces in alg name\n",
    "        result[\"algorithm_name\"] = result[\"algorithm_name\"][:-2]\n",
    "\n",
    "    if \"'\" in result[\"algorithm_name\"]:\n",
    "        # remove quotes in alg name\n",
    "        result[\"algorithm_name\"] = result[\"algorithm_name\"].replace(\"'\", \"\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def filter_results(results):\n",
    "    return [postprocess_result(r) for r in results if not remove_result_if(r)]\n",
    "    \n",
    "\n",
    "results = filter_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Basic Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print_results_info(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Per Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print_results_info_per_alg(results, exclude_results_with_eq_oracle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if len(get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result)) > 1:\n",
    "    kwargs[\"group_by\"] = \"glitch_percent\" \n",
    "\n",
    "#if GROUP_BY_MODEL:\n",
    "#    kwargs[\"group_by\"] = \"original_automaton\"\n",
    "\n",
    "bar_chart_per_algorithm_and_oracle(results, \"learned_correctly\", stat_method=np.mean, only_if=is_valid_result, **kwargs)\n",
    "bar_chart_per_algorithm_and_oracle(results, \"Precision\", stat_method=np.mean, only_if=is_valid_result, **kwargs)\n",
    "bar_chart_per_algorithm_and_oracle(results, \"Recall\", stat_method=np.mean, only_if=is_valid_result, **kwargs)\n",
    "bar_chart_per_algorithm_and_oracle(results, \"F-Score\", stat_method=np.mean, only_if=is_valid_result, **kwargs)\n",
    "bar_chart_per_algorithm_and_oracle(results, \"Precision (all traces)\", stat_method=np.mean, only_if=is_valid_result, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Per number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if len(get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result)) > 1:\n",
    "    kwargs[\"group_by\"] = \"glitch_percent\" \n",
    "\n",
    "if GROUP_BY_MODEL:\n",
    "    kwargs[\"group_by\"] = \"original_automaton\"\n",
    "\n",
    "min_num_states = min(r['original_automaton_size'] for r in results)\n",
    "max_num_states = max(r['original_automaton_size'] for r in results)\n",
    "\n",
    "def valid_and_correct_num_states(res, num_states):\n",
    "    if not is_valid_result(res):\n",
    "        return False\n",
    "    return res[\"original_automaton_size\"] == num_states\n",
    "    \n",
    "\n",
    "for num_states in range(min_num_states, max_num_states + 1):\n",
    "    bar_chart_per_algorithm_and_oracle(results, \"learned_correctly\", stat_method=np.mean, \n",
    "                                       only_if=lambda res, ns=num_states: valid_and_correct_num_states(res, ns), \n",
    "                                       title=f\"learned_correctly for {num_states} states\", **kwargs)\n",
    "    bar_chart_per_algorithm_and_oracle(results, \"Precision\", stat_method=np.mean, \n",
    "                                       only_if=lambda res, ns=num_states: valid_and_correct_num_states(res, ns),\n",
    "                                       title=f\"Precision for {num_states} states\", **kwargs)\n",
    "    bar_chart_per_algorithm_and_oracle(results, \"Recall\", stat_method=np.mean, \n",
    "                                       only_if=lambda res, ns=num_states: valid_and_correct_num_states(res, ns), \n",
    "                                       title=f\"Recall for {num_states} states\", **kwargs)\n",
    "    bar_chart_per_algorithm_and_oracle(results, \"F-Score\", stat_method=np.mean, \n",
    "                                       only_if=lambda res, ns=num_states: valid_and_correct_num_states(res, ns), \n",
    "                                       title=f\"F-Score for {num_states} states\", **kwargs)\n",
    "    bar_chart_per_algorithm_and_oracle(results, \"Precision (all traces)\", stat_method=np.mean, \n",
    "                                       only_if=lambda res, ns=num_states: valid_and_correct_num_states(res, ns), \n",
    "                                       title=f\"Precision (all traces) for {num_states} states\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Line chart over states (one plot per algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS = 'learned_correctly', 'Precision', 'Recall', 'F-Score', 'Precision (all traces)'\n",
    "ALGORITHMS = 'all'\n",
    "ORACLES = 'all'\n",
    "CHART_TYPE = 'line'  # one of 'bar', 'line'\n",
    "\n",
    "algs = ALGORITHMS\n",
    "if ALGORITHMS == 'all':\n",
    "    algs = get_algorithm_names(results)\n",
    "\n",
    "eq_oracles = ORACLES    \n",
    "if ORACLES == 'all':\n",
    "    eq_oracles = get_oracle_names(results)\n",
    "\n",
    "glitch_percentages = get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result) \n",
    "\n",
    "for glitch_percentage in glitch_percentages:\n",
    "    display(Markdown(f'#### {glitch_percentage}% glitches'))\n",
    "    for (a, o) in itertools.product(algs, eq_oracles):\n",
    "        display(Markdown(f'##### {a}, {o}'))\n",
    "        \n",
    "        if CHART_TYPE == 'bar':\n",
    "            for stat in STATS:\n",
    "                bar_chart_per_number_of_original_states(results, stat, stat_method=np.mean, \n",
    "                                                        only_if=lambda res: res['algorithm_name'] == a \n",
    "                                                                            and res['oracle'] == o\n",
    "                                                                            and res['glitch_percent'] == glitch_percentage\n",
    "                                                                            and is_valid_result(res))\n",
    "                \n",
    "        elif CHART_TYPE == 'line':\n",
    "            line_chart_per_number_of_original_states(results, *STATS, stat_method=np.mean,\n",
    "                                                     only_if=lambda res: res['algorithm_name'] == a\n",
    "                                                                         and res['oracle'] == o\n",
    "                                                                         and res['glitch_percent'] == glitch_percentage\n",
    "                                                                         and is_valid_result(res))\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Chart type {CHART_TYPE} not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Line chart over states (one plot per stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "STATS = 'learned_correctly', 'Precision', 'Recall', 'F-Score', 'Precision (all traces)'\n",
    "ALGORITHMS = 'all'\n",
    "ORACLES = 'all'\n",
    "CHART_TYPE = 'line'  # one of 'bar', 'line'\n",
    "\n",
    "algs = ALGORITHMS\n",
    "if ALGORITHMS == 'all':\n",
    "    algs = get_algorithm_names(results)\n",
    "\n",
    "eq_oracles = ORACLES    \n",
    "if ORACLES == 'all':\n",
    "    eq_oracles = get_oracle_names(results)\n",
    "\n",
    "glitch_percentages = get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result) \n",
    "\n",
    "for glitch_percentage in glitch_percentages:\n",
    "    display(Markdown(f'#### {glitch_percentage}% glitches'))\n",
    "    for stat in STATS:\n",
    "        display(Markdown(f'##### {stat}'))\n",
    "        \n",
    "        if CHART_TYPE == 'bar':\n",
    "            for (a, o) in itertools.product(algs, eq_oracles):\n",
    "                bar_chart_per_number_of_original_states(results, stat, stat_method=np.mean, \n",
    "                                                        only_if=lambda res: res['algorithm_name'] == a \n",
    "                                                                            and res['oracle'] == o\n",
    "                                                                            and res['glitch_percent'] == glitch_percentage\n",
    "                                                                            and is_valid_result(res))\n",
    "                \n",
    "        elif CHART_TYPE == 'line':\n",
    "            line_chart_per_number_of_original_states_per_alg_and_orac(results, stat, stat_method=np.mean,\n",
    "                                                                      algs=algs, oracles=eq_oracles,\n",
    "                                                                      only_if=lambda res: is_valid_result(res)\n",
    "                                                                                          and res['glitch_percent'] == glitch_percentage)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Chart type {CHART_TYPE} not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Number of Steps/Queries  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Overall bar charts per algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if len(get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result)) > 1:\n",
    "    kwargs[\"group_by\"] = \"glitch_percent\" \n",
    "\n",
    "if GROUP_BY_MODEL:\n",
    "    kwargs[\"group_by\"] = \"original_automaton\"\n",
    "\n",
    "\n",
    "bar_chart_per_algorithm_and_oracle(results, 'steps_learning', stat_method=np.mean, only_if=is_valid_result, **kwargs)\n",
    "bar_chart_per_algorithm_and_oracle(results, 'queries_learning', stat_method=np.mean, only_if=is_valid_result, **kwargs)\n",
    "bar_chart_per_algorithm_and_oracle(results, 'steps_eq_oracle', stat_method=np.mean, only_if=is_valid_result, **kwargs)\n",
    "bar_chart_per_algorithm_and_oracle(results, 'queries_eq_oracle', stat_method=np.mean, only_if=is_valid_result, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Overall bar charts per algorithm, without MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if len(get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result)) > 1:\n",
    "    kwargs[\"group_by\"] = \"glitch_percent\" \n",
    "\n",
    "if GROUP_BY_MODEL:\n",
    "    kwargs[\"group_by\"] = \"original_automaton\"\n",
    "\n",
    "def non_mat(res):\n",
    "    if not is_valid_result(res):\n",
    "        return False\n",
    "    return res[\"oracle\"] in (None, \"None\")\n",
    "\n",
    "bar_chart_per_algorithm_and_oracle(results, 'steps_learning', stat_method=np.mean, only_if=non_mat, **kwargs)\n",
    "bar_chart_per_algorithm_and_oracle(results, 'queries_learning', stat_method=np.mean, only_if=non_mat, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Seperate bar per algorithm for each number of states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if len(get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result)) > 1:\n",
    "    kwargs[\"group_by\"] = \"glitch_percent\" \n",
    "\n",
    "if GROUP_BY_MODEL:\n",
    "    kwargs[\"group_by\"] = \"original_automaton\"\n",
    "\n",
    "\n",
    "min_num_states = min(r['original_automaton_size'] for r in results)\n",
    "max_num_states = max(r['original_automaton_size'] for r in results)\n",
    "\n",
    "def valid_and_correct_num_states(res, num_states):\n",
    "    if not is_valid_result(res):\n",
    "        return False\n",
    "    return res[\"original_automaton_size\"] == num_states\n",
    "    \n",
    "\n",
    "for num_states in range(min_num_states, max_num_states + 1):\n",
    "    bar_chart_per_algorithm_and_oracle(results, \"steps_learning\", stat_method=np.mean, \n",
    "                                       only_if=lambda res, ns=num_states: valid_and_correct_num_states(res, ns), \n",
    "                                       title=f\"steps_learning for {num_states} states\", **kwargs)\n",
    "    bar_chart_per_algorithm_and_oracle(results, \"queries_learning\", stat_method=np.mean, \n",
    "                                       only_if=lambda res, ns=num_states: valid_and_correct_num_states(res, ns),\n",
    "                                       title=f\"queries_learning for {num_states} states\", **kwargs)\n",
    "    bar_chart_per_algorithm_and_oracle(results, \"steps_eq_oracle\", stat_method=np.mean, \n",
    "                                       only_if=lambda res, ns=num_states: valid_and_correct_num_states(res, ns), \n",
    "                                       title=f\"steps_eq_oracle for {num_states} states\", **kwargs)\n",
    "    bar_chart_per_algorithm_and_oracle(results, \"queries_eq_oracle\", stat_method=np.mean, \n",
    "                                       only_if=lambda res, ns=num_states: valid_and_correct_num_states(res, ns), \n",
    "                                       title=f\"queries_eq_oracle for {num_states} states\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Line charts over number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "METRICS = 'steps_learning', 'queries_learning'\n",
    "ALGORITHMS = 'all'\n",
    "ORACLES = 'all'\n",
    "CHART_TYPE = 'line'  # one of 'bar', 'line'\n",
    "\n",
    "algs = ALGORITHMS\n",
    "if ALGORITHMS == 'all':\n",
    "    algs = get_algorithm_names(results)\n",
    "\n",
    "eq_oracles = ORACLES    \n",
    "if ORACLES == 'all':\n",
    "    eq_oracles = get_oracle_names(results)\n",
    "\n",
    "glitch_percentages = get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result) \n",
    "\n",
    "for glitch_percentage in glitch_percentages:\n",
    "    display(Markdown(f'#### {glitch_percentage}% glitches'))\n",
    "    for metric in METRICS:\n",
    "        display(Markdown(f'##### {metric}'))\n",
    "        \n",
    "        if CHART_TYPE == 'bar':\n",
    "            for (a, o) in itertools.product(algs, eq_oracles):\n",
    "                bar_chart_per_number_of_original_states(results, metric, stat_method=np.mean, \n",
    "                                                        only_if=lambda res: res['algorithm_name'] == a \n",
    "                                                                            and res['oracle'] == o\n",
    "                                                                            and res['glitch_percent'] == glitch_percentage\n",
    "                                                                            and is_valid_result(res))\n",
    "                \n",
    "        elif CHART_TYPE == 'line':\n",
    "            line_chart_per_number_of_original_states_per_alg_and_orac(results, metric, stat_method=np.mean,\n",
    "                                                                      algs=algs, oracles=eq_oracles,\n",
    "                                                                      only_if=lambda res: is_valid_result(res)\n",
    "                                                                                          and res['glitch_percent'] == glitch_percentage)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Chart type {CHART_TYPE} not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Number of additional traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Stacked bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "glitch_percentages = get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result) \n",
    "\n",
    "for glitch_percentage in glitch_percentages:\n",
    "    display(Markdown(f'#### {glitch_percentage}% glitches'))\n",
    "    stacked_bar_chart_add_traces_per_algorithm_and_oracle(results, None, None, \n",
    "                                                          only_if=lambda res: is_valid_result(res) and res['glitch_percent'] == glitch_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if len(get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result)) > 1:\n",
    "    kwargs[\"group_by\"] = \"glitch_percent\" \n",
    "\n",
    "if GROUP_BY_MODEL:\n",
    "    kwargs[\"group_by\"] = \"original_automaton\"\n",
    "\n",
    "\n",
    "for add_traces_name in ['preprocessing_input_completeness', 'postprocessing_glitch', 'postprocessing_window_cex', 'postprocessing_replay', 'postprocessing_random_walks', 'postprocessing_cex', 'postprocessing_transition_coverage']:\n",
    "    def get(res, name=add_traces_name):\n",
    "        summed_num_traces = 0\n",
    "        for learning_round, info in res[\"detailed_learning_info\"].items():\n",
    "            summed_num_traces += len(info.get(f\"additional_traces_{name}\", []))\n",
    "        return summed_num_traces\n",
    "    get.__name__ = f'len({add_traces_name})'\n",
    "    bar_chart_per_algorithm_and_oracle(results, get, stat_method=np.mean, only_if=is_valid_result, **kwargs)\n",
    "    bar_chart_per_algorithm_and_oracle(results, get, stat_method=np.sum, only_if=is_valid_result, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Line charts over learning rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import functools    \n",
    "def num_traces(result: dict, add_traces_name: str):\n",
    "    return len(result.get(add_traces_name, []))\n",
    "    \n",
    "for add_traces in ('preprocessing_input_completeness', 'postprocessing_glitch', 'postprocessing_replay', 'postprocessing_random_walks', 'postprocessing_cex'):\n",
    "    func = functools.partial(num_traces, add_traces_name=f\"additional_traces_{add_traces}\")\n",
    "    func.__name__ = f\"len({add_traces})\"\n",
    "    line_chart_over_learning_rounds(results, key=func, only_if=is_valid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Time-Outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if len(get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result)) > 1:\n",
    "    kwargs[\"group_by\"] = \"glitch_percent\" \n",
    "\n",
    "if GROUP_BY_MODEL:\n",
    "    kwargs[\"group_by\"] = \"original_automaton\"\n",
    "\n",
    "\n",
    "bar_chart_per_algorithm_and_oracle(results, \"timed_out\", stat_method=np.sum, only_if=is_valid_result, **kwargs)\n",
    "bar_chart_per_number_of_original_states(results, 'timed_out', stat_method=np.sum, only_if=is_valid_result)\n",
    "line_chart_per_number_of_original_states_per_alg_and_orac(results, 'timed_out', get_algorithm_names(results), get_oracle_names(results), stat_method=np.sum, only_if=is_valid_result)\n",
    "bar_chart_per_algorithm_and_oracle(results, 'learning_rounds', stat_method=np.mean, \n",
    "                                   only_if=lambda res: is_valid_result(res) and res[\"timed_out\"],\n",
    "                                   title=\"Mean number of learning rounds for timed out calls\", **kwargs)\n",
    "\n",
    "def last_num_traces(result: dict):\n",
    "    max_round = max(int(i) for i in result['detailed_learning_info'].keys())\n",
    "    return result['detailed_learning_info'][str(max_round)][\"num_traces\"]\n",
    "\n",
    "bar_chart_per_algorithm_and_oracle(results, last_num_traces, stat_method=np.mean, only_if=lambda res: is_valid_result(res) and res[\"timed_out\"],\n",
    "                                   title=\"Mean number of traces in last round for timed out calls\", **kwargs)\n",
    "\n",
    "bar_chart_per_algorithm_and_oracle(results, 'total_time', stat_method=np.sum, only_if=lambda res: is_valid_result(res) and res[\"timed_out\"], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Learning Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart_per_algorithm_and_oracle(results, \"learning_rounds\", stat_method=np.mean, only_if=is_valid_result, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if len(get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result)) > 1:\n",
    "    kwargs[\"group_by\"] = \"glitch_percent\" \n",
    "\n",
    "if GROUP_BY_MODEL:\n",
    "    kwargs[\"group_by\"] = \"original_automaton\"\n",
    "\n",
    "\n",
    "bar_chart_per_algorithm_and_oracle(results, \"total_time\", stat_method=np.mean, only_if=is_valid_result, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### Per number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHMS = 'all'\n",
    "ORACLES = (\"None\", )# 'all'\n",
    "CHART_TYPE = 'line'  # one of 'bar', 'line'\n",
    "\n",
    "algs = ALGORITHMS\n",
    "if ALGORITHMS == 'all':\n",
    "    algs = get_algorithm_names(results)\n",
    "\n",
    "eq_oracles = ORACLES    \n",
    "if ORACLES == 'all':\n",
    "    eq_oracles = get_oracle_names(results)\n",
    "\n",
    "glitch_percentages = get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result) \n",
    "\n",
    "for glitch_percentage in glitch_percentages:\n",
    "    display(Markdown(f'#### {glitch_percentage}% glitches'))\n",
    "    if CHART_TYPE == 'bar':\n",
    "        for (a, o) in itertools.product(algs, eq_oracles):\n",
    "            bar_chart_per_number_of_original_states(results, \"total_time\", stat_method=np.mean, \n",
    "                                                    only_if=lambda res: res['algorithm_name'] == a \n",
    "                                                                        and res['oracle'] == o\n",
    "                                                                        and res['glitch_percent'] == glitch_percentage\n",
    "                                                                        and is_valid_result(res))\n",
    "            \n",
    "    elif CHART_TYPE == 'line':\n",
    "        line_chart_per_number_of_original_states_per_alg_and_orac(results, \"total_time\", stat_method=np.mean,\n",
    "                                                                  algs=algs, oracles=eq_oracles,\n",
    "                                                                  only_if=lambda res: is_valid_result(res)\n",
    "                                                                                      and res['glitch_percent'] == glitch_percentage)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Chart type {CHART_TYPE} not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def highest_score(learning_round_info: dict):\n",
    "    if \"heuristic_scores\" not in learning_round_info:\n",
    "        return -1\n",
    "    return max(learning_round_info[\"heuristic_scores\"].values())\n",
    "\n",
    "def best_num_states(learning_round_info: dict):\n",
    "    if \"heuristic_scores\" not in learning_round_info:\n",
    "        return -1\n",
    "    return int(max(learning_round_info[\"heuristic_scores\"], key=learning_round_info[\"heuristic_scores\"].get))\n",
    "\n",
    "def distance_of_peak_to_true_num_states(result: dict, step: int):\n",
    "    peak_num_states = best_num_states(result[\"detailed_learning_info\"][str(step)])\n",
    "    true_num_states = result[\"original_automaton_size\"]\n",
    "    if peak_num_states == -1:\n",
    "        if step == 1:\n",
    "            return result[\"original_automaton_num_outputs\"] - true_num_states\n",
    "        else:\n",
    "            return distance_of_peak_to_true_num_states(result, step - 1)\n",
    "    return peak_num_states - true_num_states\n",
    "\n",
    "for alg, orac in itertools.product(get_algorithm_names(results), get_oracle_names(results)):\n",
    "    display(Markdown(f'#### {alg}/{orac}'))\n",
    "    line_chart_over_learning_rounds(results, key=distance_of_peak_to_true_num_states,\n",
    "                                    only_if=lambda res: is_valid_result(res) \n",
    "                                                        and res[\"algorithm_name\"] == alg \n",
    "                                                        and res[\"oracle\"] == orac, \n",
    "                                    get_from_full_result=True, \n",
    "                                    colorcode_by_alg=False)\n",
    "    #line_chart_over_learning_rounds(results, key=highest_score,\n",
    "    #                                only_if=lambda res: is_valid_result(res) \n",
    "    #                                                    and res[\"algorithm_name\"] == alg \n",
    "    #                                                    and res[\"oracle\"] == orac, \n",
    "    #                                stay_at_last_val=lambda val: val == -1,\n",
    "    #                                colorcode_by_alg=False)\n",
    "    #line_chart_over_learning_rounds(results, key=best_num_states, \n",
    "    #                                only_if=lambda res: is_valid_result(res) \n",
    "    #                                                    and res[\"algorithm_name\"] == alg \n",
    "    #                                                    and res[\"oracle\"] == orac, \n",
    "    #                                stay_at_last_val=lambda val: val == -1,\n",
    "    #                                colorcode_by_alg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if len(get_all_possible_values_for_key(results, \"glitch_percent\", only_if=is_valid_result)) > 1:\n",
    "    kwargs[\"group_by\"] = \"glitch_percent\" \n",
    "\n",
    "def num_rounds_with_returned_peak(result: dict):\n",
    "    returned_peak = best_num_states(result[\"detailed_learning_info\"][str(result[\"learning_rounds\"])])\n",
    "    c = 0\n",
    "    for step in range(result[\"learning_rounds\"], 0, -1):\n",
    "        if best_num_states(result[\"detailed_learning_info\"][str(step)]) == returned_peak:\n",
    "            c += 1\n",
    "        else:\n",
    "            break\n",
    "    return c\n",
    "        \n",
    "bar_chart_per_algorithm_and_oracle(results, num_rounds_with_returned_peak, stat_method=np.mean, only_if=is_valid_result, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## Transition / State Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from aalpy import load_automaton_from_file\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_algorithms(results):\n",
    "    \"\"\"Analyzes and compares transition behavior across multiple algorithms.\"\"\"\n",
    "    \n",
    "    # Organize data by algorithm\n",
    "    algorithm_data = defaultdict(list)\n",
    "    original_automata = {}\n",
    "\n",
    "    for entry in results:\n",
    "        algo_name = entry[\"algorithm_name\"]\n",
    "        taken_transitions = entry[\"sul_transitions\"]\n",
    "        original_automaton = load_automaton_from_file(entry[\"original_automaton\"], \"moore\")\n",
    "\n",
    "        algorithm_data[algo_name].append(taken_transitions)\n",
    "        original_automata[algo_name] = original_automaton  # Assume all runs of algo use same original automaton\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    transition_counts = {algo: defaultdict(list) for algo in algorithm_data}\n",
    "    extra_transitions = {algo: defaultdict(int) for algo in algorithm_data}\n",
    "\n",
    "    for algo, runs in algorithm_data.items():\n",
    "        # original_transitions = original_automata[algo][\"transitions\"]  # Assuming this structure\n",
    "\n",
    "        for run in runs:\n",
    "            for state, inputs in run.items():\n",
    "                for inp, transitions in inputs.items():\n",
    "                    for target, count in transitions.items():\n",
    "                        transition_counts[algo][(state, inp, target)].append(count)\n",
    "\n",
    "                        # # Count extra transitions (not in original automaton)\n",
    "                        # if (state, inp, target) not in original_transitions:\n",
    "                        #     extra_transitions[algo][(state, inp, target)] += count\n",
    "\n",
    "    # Compute summary statistics\n",
    "    summary_stats = {}\n",
    "    for algo, counts in transition_counts.items():\n",
    "        all_counts = [np.sum(v) for v in counts.values()]\n",
    "        summary_stats[algo] = {\n",
    "            \"min\": np.min(all_counts),\n",
    "            \"max\": np.max(all_counts),\n",
    "            \"mean\": np.mean(all_counts),\n",
    "            \"median\": np.median(all_counts),\n",
    "            \"std_dev\": np.std(all_counts),\n",
    "            # \"extra_transitions\": sum(extra_transitions[algo].values())\n",
    "        }\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"\\n### Transition Statistics per Algorithm ###\\n\")\n",
    "    for algo, stats in summary_stats.items():\n",
    "        print(f\"Algorithm: {algo}\")\n",
    "        print(f\"  Min Transitions: {stats['min']}\")\n",
    "        print(f\"  Max Transitions: {stats['max']}\")\n",
    "        print(f\"  Mean Transitions: {stats['mean']:.2f}\")\n",
    "        print(f\"  Median Transitions: {stats['median']}\")\n",
    "        print(f\"  Std Dev: {stats['std_dev']:.2f}\")\n",
    "        # print(f\"  Extra Transitions: {stats['extra_transitions']}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    # Plot comparison\n",
    "    plot_transition_distributions(transition_counts)\n",
    "    plot_transition_differences(transition_counts)\n",
    "\n",
    "def plot_transition_distributions(transition_counts):\n",
    "    \"\"\"Plots bar graphs of transition frequencies per algorithm.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    for algo, counts in transition_counts.items():\n",
    "        all_counts = [np.sum(v) for v in counts.values()]\n",
    "        plt.hist(all_counts, bins=20, alpha=0.5, label=algo)\n",
    "\n",
    "    plt.xlabel(\"Transition Count\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Transition Frequency Distribution\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_transition_differences(transition_counts):\n",
    "    \"\"\"Plots scatter plots to compare transition differences between two algorithms.\"\"\"\n",
    "    if len(transition_counts) != 2:\n",
    "        return  # Only makes sense for 2 algorithms\n",
    "\n",
    "    algo1, algo2 = list(transition_counts.keys())\n",
    "    shared_transitions = set(transition_counts[algo1].keys()) & set(transition_counts[algo2].keys())\n",
    "\n",
    "    diffs = []\n",
    "    for t in shared_transitions:\n",
    "        mean_algo1 = np.mean(transition_counts[algo1][t])\n",
    "        mean_algo2 = np.mean(transition_counts[algo2][t])\n",
    "        diffs.append((mean_algo1, mean_algo2))\n",
    "\n",
    "    x, y = zip(*diffs)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(x, y, alpha=0.6)\n",
    "    plt.plot([min(x), max(x)], [min(x), max(x)], 'r--')  # Identity line\n",
    "    plt.xlabel(f\"{algo1} Mean Transitions\")\n",
    "    plt.ylabel(f\"{algo2} Mean Transitions\")\n",
    "    plt.title(\"Per-Transition Differences\")\n",
    "    plt.show()\n",
    "\n",
    "# analyze_algorithms(results)  # ai generated - not incredibly useful currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from aalpy.utils import load_automaton_from_file\n",
    "from aalpy import MooreMachine\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "def transition_statistics(result: dict,\n",
    "                          transition_coverage_frequency_threshold = 1,\n",
    "                          transition_coverage_frequency_threshold_mode = 'absolute'):\n",
    "    transitions = TracedMooreSUL.flatten_transitions_dict(result[\"sul_transitions\"])\n",
    "\n",
    "    original_automaton: MooreMachine = load_automaton_from_file(result[\"original_automaton\"], \"moore\")\n",
    "\n",
    "    glitched_freqs = []\n",
    "    dominant_freqs = []\n",
    "    for (s1, l, s2), trans_count in transitions.items():\n",
    "        s1 = original_automaton.get_state_by_id(s1)\n",
    "        s2 = original_automaton.get_state_by_id(s2)\n",
    "        \n",
    "        if l not in s1.transitions:\n",
    "            # JSON serialization made our int-transitions into strings - revert\n",
    "            l = int(l)\n",
    "            \n",
    "        if s1.transitions[l] != s2:\n",
    "            glitched_freqs.append(trans_count)\n",
    "        else:\n",
    "            dominant_freqs.append(trans_count)\n",
    "\n",
    "    total_num_glitches = sum(g for g in glitched_freqs)\n",
    "    total_num_dominant = sum(d for d in dominant_freqs)\n",
    "    total_num_steps = total_num_glitches + total_num_dominant\n",
    "    # assert total_num_steps == result[\"steps_learning\"], f\"number of steps does not match\" # TODO un-comment\n",
    "\n",
    "    glitch_percentage = total_num_glitches / total_num_steps * 100\n",
    "\n",
    "    possible_transitions = 0\n",
    "    taken_transitions = 0\n",
    "\n",
    "    if transition_coverage_frequency_threshold_mode == 'absolute':\n",
    "        threshold = transition_coverage_frequency_threshold\n",
    "    elif transition_coverage_frequency_threshold_mode == 'relative':\n",
    "        threshold = total_num_steps * transition_coverage_frequency_threshold\n",
    "    else:\n",
    "        raise NotImplementedError(transition_coverage_frequency_threshold_mode)\n",
    "\n",
    "    for s1 in original_automaton.states:\n",
    "        for l, s2 in s1.transitions.items():\n",
    "            possible_transitions += 1\n",
    "\n",
    "            if (s1.state_id, l, s2.state_id) not in transitions:\n",
    "                # see above; JSON serialization\n",
    "                l = str(l)\n",
    "            \n",
    "            if transitions[(s1.state_id, l, s2.state_id)] >= threshold:\n",
    "                taken_transitions += 1\n",
    "\n",
    "    return {\n",
    "        \"glitched_freqs\": glitched_freqs,\n",
    "        \"dominant_freqs\": dominant_freqs,\n",
    "\n",
    "        \"glitch_percentage\": glitch_percentage,\n",
    "\n",
    "        \"total_num_steps\": total_num_steps,\n",
    "        \"total_num_glitches\": total_num_glitches,\n",
    "        \"total_num_dominant\": total_num_dominant,\n",
    "\n",
    "        \"max_glitched_freq\": max(glitched_freqs),\n",
    "        \"mean_glitched_freq\": np.mean(glitched_freqs),\n",
    "        \"median_glitched_freq\": np.median(glitched_freqs),\n",
    "\n",
    "        \"min_dominant_freq\": min(dominant_freqs),\n",
    "        \"max_dominant_freq\": max(dominant_freqs),\n",
    "        \"mean_dominant_freq\": np.mean(dominant_freqs),\n",
    "        \"median_dominant_freq\": np.median(dominant_freqs),\n",
    "\n",
    "        \"transition_coverage\": taken_transitions / possible_transitions,\n",
    "    }\n",
    "\n",
    "def transition_stat(key: str):\n",
    "    def fun(res):\n",
    "        return transition_statistics(res)[key]\n",
    "    fun.__name__ = key\n",
    "    return fun\n",
    "\n",
    "def n_frequent_transition_coverage(threshold: int):\n",
    "    def fun(res):\n",
    "        return transition_statistics(res, threshold,\n",
    "                                     transition_coverage_frequency_threshold_mode='absolute')[\"transition_coverage\"]\n",
    "    fun.__name__ = f\"{threshold}-frequent transition coverage\"\n",
    "    return fun\n",
    "\n",
    "def relative_transition_coverage(threshold: float):\n",
    "    def fun(res):\n",
    "        return transition_statistics(res, threshold/100,\n",
    "                                     transition_coverage_frequency_threshold_mode='relative')[\"transition_coverage\"]\n",
    "    fun.__name__ = f\"relative transition coverage (at least {threshold}% of steps)\"\n",
    "    return fun\n",
    "\n",
    "# bar_chart_per_algorithm(results, transition_stat(\"transition_coverage\"), stat_method=np.median)\n",
    "# bar_chart_per_algorithm(results, n_frequent_transition_coverage(4), stat_method=np.mean)\n",
    "# bar_chart_per_algorithm(results, relative_transition_coverage(2), stat_method=np.median)\n",
    "# scatterplot_per_alg(results, x_key=transition_stat(\"min_dominant_freq\"), y_key=transition_stat(\"max_glitched_freq\"))\n",
    "\n",
    "def plot_transition_coverage_over_threshold(results: list[dict], mode: str, start: float, end: float, step: float, stat_method: np.mean):\n",
    "    algs = get_algorithm_names(results)\n",
    "    eq_oracles = get_oracle_names(results)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    def add_labels(line):\n",
    "        x, y = line.get_data()\n",
    "        for x, y in zip(x, y):\n",
    "            plt.annotate(f'{y:.2f}', (x, y))\n",
    "\n",
    "    marker_per_alg = {alg: marker for alg, marker in\n",
    "                      zip(algs, ['o', '*', 'p', 'h', 'd', 'v', '8', 's', 'P', 'H', 'X', '1', '2', '3' ])}\n",
    "    color_per_alg =  {alg: color for alg, color in\n",
    "                      zip(algs, mcolors.TABLEAU_COLORS)}\n",
    "    line_style_per_oracle = {orac: style for orac, style in\n",
    "                             zip(eq_oracles, ['-', ':', '-.', '--'])}\n",
    "\n",
    "    ao_to_values = {(a, o): [] for (a, o) in itertools.product(algs, eq_oracles)}\n",
    "    x_axis = np.arange(start, end, step)\n",
    "    for (a, o) in ao_to_values.keys():\n",
    "        values = []\n",
    "        for threshold in x_axis:\n",
    "            fun = n_frequent_transition_coverage(threshold) if mode == 'absolute' else relative_transition_coverage(threshold)\n",
    "            values_at_threshold = [fun(res) for res in results\n",
    "                                   if res['algorithm_name'] == a\n",
    "                                   and res['oracle'] == o]\n",
    "            values.append(stat_method(values_at_threshold))\n",
    "        alg_str = f\"{a}\" if len(eq_oracles) == 1 else f\"{a}, {o}\"\n",
    "        fmt = f\"{line_style_per_oracle[o]}{marker_per_alg[a]}\"\n",
    "        color = color_per_alg[a]\n",
    "        line, = plt.plot(x_axis, values, fmt, label=alg_str, color=color)\n",
    "        add_labels(line)\n",
    "\n",
    "    mode_str = \"N-frequent transition coverage\" if mode == 'absolute' else \"Relative transition coverage (at least N %)\"\n",
    "    plt.xlabel(f\"N (minimum {'number' if mode=='absolute' else 'percentage'} of steps for a transition to count as covered)\")\n",
    "    plt.ylabel('Transition coverage')\n",
    "    plt.title(f\"{mode_str} ({stat_method.__name__} over results)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_transition_coverage_over_threshold(results, 'absolute', 1, 15, 1, stat_method=np.mean)\n",
    "plot_transition_coverage_over_threshold(results, 'relative', 1, 5, 0.5, stat_method=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
